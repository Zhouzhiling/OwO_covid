{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this file, we will divide the counties in US into 4 groups according to their reported deaths number.\n",
    "# Then we will train different models for different groups of counties using curve fitting and DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from linear_regression import LinearRegressor\n",
    "from DNN import DNN\n",
    "from output import Output\n",
    "from model_scoring_evaluation import generate_day_tag, score_all_predictions\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First of all, we fit the death data from the counties that reported less than 14 deaths during the past two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 0. Training acc: 8.100000\n",
      "Day: 1. Training acc: 7.900000\n",
      "Day: 2. Training acc: 7.920000\n",
      "Day: 3. Training acc: 7.370000\n",
      "Day: 4. Training acc: 6.660000\n",
      "Day: 5. Training acc: 6.300000\n",
      "Day: 6. Training acc: 5.540000\n",
      "Day: 7. Training acc: 4.640000\n",
      "Day: 8. Training acc: 3.670000\n",
      "Day: 9. Training acc: 3.160000\n",
      "Day: 10. Training acc: 2.860000\n",
      "Day: 11. Training acc: 2.530000\n",
      "Day: 12. Training acc: 2.150000\n",
      "Day: 13. Training acc: 1.870000\n",
      "Predictions saved as models/LR/lr_burning.csv\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegressor()\n",
    "lr.train()\n",
    "lr.test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we can write our predictions to 'sample_submission.csv' in order to calculate pinball loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/293293\n",
      "100000/293293\n",
      "200000/293293\n",
      "Successfully saved!\n"
     ]
    }
   ],
   "source": [
    "source = 'models/LR/lr_burning.csv'\n",
    "dst = 'submissions/submission_dnn_lr_model.csv'\n",
    "output = Output()\n",
    "output.save_submission(source, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Secondly, we fit the death data from the counties that reported less than 140 deaths during the past two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day: 0. Training acc: 26.560000\n",
      "Day: 1. Training acc: 29.960000\n",
      "Day: 2. Training acc: 29.580000\n",
      "Day: 3. Training acc: 29.220000\n",
      "Day: 4. Training acc: 29.600000\n",
      "Day: 5. Training acc: 28.230000\n",
      "Day: 6. Training acc: 25.610000\n",
      "Day: 7. Training acc: 21.670000\n",
      "Day: 8. Training acc: 17.930000\n",
      "Day: 9. Training acc: 17.020000\n",
      "Day: 10. Training acc: 17.260000\n",
      "Day: 11. Training acc: 13.400000\n",
      "Day: 12. Training acc: 12.030000\n",
      "Day: 13. Training acc: 9.910000\n",
      "Predictions saved as models/LR/lr_mid.csv\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegressor()\n",
    "lr.train('mid')\n",
    "lr.test('mid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Again, we write our submission to our output file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/293293\n",
      "100000/293293\n",
      "200000/293293\n",
      "Successfully saved!\n"
     ]
    }
   ],
   "source": [
    "source = 'models/LR/lr_mid.csv'\n",
    "dst = 'submissions/submission_dnn_lr_model.csv'\n",
    "output = Output('submissions/submission_dnn_lr_model.csv')\n",
    "output.save_submission(source, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we use DNN model to fit counties with more deaths. We divide these counties into two groups and we will build different models for them.\n",
    "# So we fit the data of counties which reported more than 140 but less than 700 deaths during past two weeks using DNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 53)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               6912      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 14)                462       \n",
      "=================================================================\n",
      "Total params: 83,630\n",
      "Trainable params: 83,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "1485/1485 [==============================] - 1s 370us/step - loss: 0.9528 - mse: 0.9528\n",
      "Epoch 2/100\n",
      " 664/1485 [============>.................] - ETA: 0s - loss: 0.8026 - mse: 0.8026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.8403 - mse: 0.8403\n",
      "Epoch 3/100\n",
      "1485/1485 [==============================] - 0s 224us/step - loss: 0.7797 - mse: 0.7797\n",
      "Epoch 4/100\n",
      "1485/1485 [==============================] - 0s 225us/step - loss: 0.7402 - mse: 0.7402\n",
      "Epoch 5/100\n",
      "1485/1485 [==============================] - 0s 226us/step - loss: 0.7113 - mse: 0.7113\n",
      "Epoch 6/100\n",
      "1485/1485 [==============================] - 0s 225us/step - loss: 0.6886 - mse: 0.6886\n",
      "Epoch 7/100\n",
      "1485/1485 [==============================] - 0s 224us/step - loss: 0.6692 - mse: 0.6692\n",
      "Epoch 8/100\n",
      "1485/1485 [==============================] - 0s 225us/step - loss: 0.6530 - mse: 0.6530\n",
      "Epoch 9/100\n",
      "1485/1485 [==============================] - 0s 225us/step - loss: 0.6373 - mse: 0.6373\n",
      "Epoch 10/100\n",
      "1485/1485 [==============================] - 0s 230us/step - loss: 0.6253 - mse: 0.6253\n",
      "Epoch 11/100\n",
      "1485/1485 [==============================] - 0s 235us/step - loss: 0.6116 - mse: 0.6116\n",
      "Epoch 12/100\n",
      "1485/1485 [==============================] - 0s 228us/step - loss: 0.5996 - mse: 0.5996\n",
      "Epoch 13/100\n",
      "1485/1485 [==============================] - 0s 226us/step - loss: 0.5887 - mse: 0.5887\n",
      "Epoch 14/100\n",
      "1485/1485 [==============================] - 0s 227us/step - loss: 0.5802 - mse: 0.5802\n",
      "Epoch 15/100\n",
      "1485/1485 [==============================] - 0s 228us/step - loss: 0.5711 - mse: 0.5711\n",
      "Epoch 16/100\n",
      "1485/1485 [==============================] - 0s 233us/step - loss: 0.5585 - mse: 0.5585\n",
      "Epoch 17/100\n",
      "1485/1485 [==============================] - 0s 228us/step - loss: 0.5511 - mse: 0.5511\n",
      "Epoch 18/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.5429 - mse: 0.5429\n",
      "Epoch 19/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.5346 - mse: 0.5346\n",
      "Epoch 20/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.5249 - mse: 0.5249\n",
      "Epoch 21/100\n",
      "1485/1485 [==============================] - 0s 233us/step - loss: 0.5176 - mse: 0.5176\n",
      "Epoch 22/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.5096 - mse: 0.5096\n",
      "Epoch 23/100\n",
      "1485/1485 [==============================] - 0s 233us/step - loss: 0.5039 - mse: 0.5039\n",
      "Epoch 24/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4957 - mse: 0.4957\n",
      "Epoch 25/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.4878 - mse: 0.4878\n",
      "Epoch 26/100\n",
      "1485/1485 [==============================] - 0s 230us/step - loss: 0.4817 - mse: 0.4817\n",
      "Epoch 27/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4728 - mse: 0.4728\n",
      "Epoch 28/100\n",
      "1485/1485 [==============================] - 0s 233us/step - loss: 0.4707 - mse: 0.4707\n",
      "Epoch 29/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4630 - mse: 0.4630\n",
      "Epoch 30/100\n",
      "1485/1485 [==============================] - 0s 230us/step - loss: 0.4563 - mse: 0.4563\n",
      "Epoch 31/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.4501 - mse: 0.4501\n",
      "Epoch 32/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4451 - mse: 0.4451\n",
      "Epoch 33/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4387 - mse: 0.4387\n",
      "Epoch 34/100\n",
      "1485/1485 [==============================] - 0s 232us/step - loss: 0.4326 - mse: 0.4326\n",
      "Epoch 35/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4265 - mse: 0.4265\n",
      "Epoch 36/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.4212 - mse: 0.4212\n",
      "Epoch 37/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.4138 - mse: 0.4138\n",
      "Epoch 38/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4087 - mse: 0.4087\n",
      "Epoch 39/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4069 - mse: 0.4069\n",
      "Epoch 40/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.4002 - mse: 0.4002\n",
      "Epoch 41/100\n",
      "1485/1485 [==============================] - 0s 230us/step - loss: 0.3922 - mse: 0.3922\n",
      "Epoch 42/100\n",
      "1485/1485 [==============================] - 0s 235us/step - loss: 0.3871 - mse: 0.3871\n",
      "Epoch 43/100\n",
      "1485/1485 [==============================] - 0s 236us/step - loss: 0.3815 - mse: 0.3815\n",
      "Epoch 44/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.3770 - mse: 0.3770\n",
      "Epoch 45/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.3742 - mse: 0.3742\n",
      "Epoch 46/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.3682 - mse: 0.3682\n",
      "Epoch 47/100\n",
      "1485/1485 [==============================] - 0s 235us/step - loss: 0.3626 - mse: 0.3626\n",
      "Epoch 48/100\n",
      "1485/1485 [==============================] - 0s 235us/step - loss: 0.3589 - mse: 0.3589\n",
      "Epoch 49/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.3542 - mse: 0.3542\n",
      "Epoch 50/100\n",
      "1485/1485 [==============================] - 0s 238us/step - loss: 0.3500 - mse: 0.3500\n",
      "Epoch 51/100\n",
      "1485/1485 [==============================] - 0s 233us/step - loss: 0.3431 - mse: 0.3431\n",
      "Epoch 52/100\n",
      "1485/1485 [==============================] - 0s 235us/step - loss: 0.3433 - mse: 0.3433\n",
      "Epoch 53/100\n",
      "1485/1485 [==============================] - 0s 238us/step - loss: 0.3363 - mse: 0.3363\n",
      "Epoch 54/100\n",
      "1485/1485 [==============================] - 0s 242us/step - loss: 0.3323 - mse: 0.3323\n",
      "Epoch 55/100\n",
      "1485/1485 [==============================] - 0s 238us/step - loss: 0.3281 - mse: 0.3281\n",
      "Epoch 56/100\n",
      "1485/1485 [==============================] - 0s 248us/step - loss: 0.3255 - mse: 0.3255\n",
      "Epoch 57/100\n",
      "1485/1485 [==============================] - 0s 248us/step - loss: 0.3230 - mse: 0.3230\n",
      "Epoch 58/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.3155 - mse: 0.3155\n",
      "Epoch 59/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.3109 - mse: 0.3109\n",
      "Epoch 60/100\n",
      "1485/1485 [==============================] - 0s 247us/step - loss: 0.3058 - mse: 0.3058\n",
      "Epoch 61/100\n",
      "1485/1485 [==============================] - 0s 247us/step - loss: 0.3027 - mse: 0.3027\n",
      "Epoch 62/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.3015 - mse: 0.3015\n",
      "Epoch 63/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.2956 - mse: 0.2956\n",
      "Epoch 64/100\n",
      "1485/1485 [==============================] - 0s 248us/step - loss: 0.2943 - mse: 0.2943\n",
      "Epoch 65/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.2906 - mse: 0.2906\n",
      "Epoch 66/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.2851 - mse: 0.2851\n",
      "Epoch 67/100\n",
      "1485/1485 [==============================] - 0s 250us/step - loss: 0.2822 - mse: 0.2822\n",
      "Epoch 68/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.2808 - mse: 0.2808\n",
      "Epoch 69/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.2781 - mse: 0.2781\n",
      "Epoch 70/100\n",
      "1485/1485 [==============================] - 0s 247us/step - loss: 0.2757 - mse: 0.2757\n",
      "Epoch 71/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.2718 - mse: 0.2718\n",
      "Epoch 72/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.2689 - mse: 0.2689\n",
      "Epoch 73/100\n",
      "1485/1485 [==============================] - 0s 248us/step - loss: 0.2619 - mse: 0.2619\n",
      "Epoch 74/100\n",
      "1485/1485 [==============================] - 0s 248us/step - loss: 0.2586 - mse: 0.2586\n",
      "Epoch 75/100\n",
      "1485/1485 [==============================] - 0s 248us/step - loss: 0.2577 - mse: 0.2577\n",
      "Epoch 76/100\n",
      "1485/1485 [==============================] - 0s 247us/step - loss: 0.2531 - mse: 0.2531\n",
      "Epoch 77/100\n",
      "1485/1485 [==============================] - 0s 250us/step - loss: 0.2507 - mse: 0.2507\n",
      "Epoch 78/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.2488 - mse: 0.2488\n",
      "Epoch 79/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.2463 - mse: 0.2463\n",
      "Epoch 80/100\n",
      "1485/1485 [==============================] - 0s 246us/step - loss: 0.2417 - mse: 0.2417\n",
      "Epoch 81/100\n",
      "1485/1485 [==============================] - 0s 255us/step - loss: 0.2393 - mse: 0.2393\n",
      "Epoch 82/100\n",
      "1485/1485 [==============================] - 0s 260us/step - loss: 0.2381 - mse: 0.2381\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485/1485 [==============================] - 0s 250us/step - loss: 0.2343 - mse: 0.2343\n",
      "Epoch 84/100\n",
      "1485/1485 [==============================] - 0s 254us/step - loss: 0.2325 - mse: 0.2325\n",
      "Epoch 85/100\n",
      "1485/1485 [==============================] - 0s 249us/step - loss: 0.2307 - mse: 0.2307\n",
      "Epoch 86/100\n",
      "1485/1485 [==============================] - 0s 239us/step - loss: 0.2315 - mse: 0.2315\n",
      "Epoch 87/100\n",
      "1485/1485 [==============================] - 0s 240us/step - loss: 0.2254 - mse: 0.2254\n",
      "Epoch 88/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.2192 - mse: 0.2192\n",
      "Epoch 89/100\n",
      "1485/1485 [==============================] - 0s 227us/step - loss: 0.2184 - mse: 0.2184\n",
      "Epoch 90/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.2152 - mse: 0.2152\n",
      "Epoch 91/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.2146 - mse: 0.2146\n",
      "Epoch 92/100\n",
      "1485/1485 [==============================] - 0s 233us/step - loss: 0.2127 - mse: 0.2127\n",
      "Epoch 93/100\n",
      "1485/1485 [==============================] - 0s 230us/step - loss: 0.2088 - mse: 0.2088\n",
      "Epoch 94/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.2069 - mse: 0.2069\n",
      "Epoch 95/100\n",
      "1485/1485 [==============================] - 0s 230us/step - loss: 0.2023 - mse: 0.2023\n",
      "Epoch 96/100\n",
      "1485/1485 [==============================] - 0s 232us/step - loss: 0.1997 - mse: 0.1997\n",
      "Epoch 97/100\n",
      "1485/1485 [==============================] - 0s 229us/step - loss: 0.1995 - mse: 0.1995\n",
      "Epoch 98/100\n",
      "1485/1485 [==============================] - 0s 232us/step - loss: 0.1956 - mse: 0.1956\n",
      "Epoch 99/100\n",
      "1485/1485 [==============================] - 0s 231us/step - loss: 0.1948 - mse: 0.1948\n",
      "Epoch 100/100\n",
      "1485/1485 [==============================] - 0s 234us/step - loss: 0.1949 - mse: 0.1949\n",
      "Predictions saved as models/DNN/dnn_mid2.csv\n"
     ]
    }
   ],
   "source": [
    "dnn = DNN('mid2')\n",
    "dnn.train()\n",
    "dnn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/293293\n",
      "100000/293293\n",
      "200000/293293\n",
      "Successfully saved!\n"
     ]
    }
   ],
   "source": [
    "source = 'models/DNN/dnn_mid2.csv'\n",
    "dst = 'submissions/submission_dnn_lr_model.csv'\n",
    "output = Output('submissions/submission_dnn_lr_model.csv')\n",
    "output.save_submission(source, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we fit the data of counties which reported more than 700 deaths during past two weeks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 53)                0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 128)               6912      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 14)                462       \n",
      "=================================================================\n",
      "Total params: 83,630\n",
      "Trainable params: 83,630\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "138/138 [==============================] - 0s 1ms/step - loss: 0.9926 - mse: 0.9926\n",
      "Epoch 2/100\n",
      "138/138 [==============================] - 0s 356us/step - loss: 0.8883 - mse: 0.8883\n",
      "Epoch 3/100\n",
      "138/138 [==============================] - 0s 313us/step - loss: 0.7944 - mse: 0.7944\n",
      "Epoch 4/100\n",
      "138/138 [==============================] - 0s 264us/step - loss: 0.7033 - mse: 0.7033\n",
      "Epoch 5/100\n",
      "138/138 [==============================] - 0s 265us/step - loss: 0.6271 - mse: 0.6271\n",
      "Epoch 6/100\n",
      "  4/138 [..............................] - ETA: 0s - loss: 0.1537 - mse: 0.1537"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:1042: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "/opt/anaconda3/lib/python3.7/site-packages/keras/callbacks/callbacks.py:846: RuntimeWarning: Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,mse,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 260us/step - loss: 0.5631 - mse: 0.5631\n",
      "Epoch 7/100\n",
      "138/138 [==============================] - 0s 248us/step - loss: 0.5084 - mse: 0.5084\n",
      "Epoch 8/100\n",
      "138/138 [==============================] - 0s 241us/step - loss: 0.4608 - mse: 0.4608\n",
      "Epoch 9/100\n",
      "138/138 [==============================] - 0s 239us/step - loss: 0.4168 - mse: 0.4168\n",
      "Epoch 10/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.3752 - mse: 0.3752\n",
      "Epoch 11/100\n",
      "138/138 [==============================] - 0s 241us/step - loss: 0.3432 - mse: 0.3432\n",
      "Epoch 12/100\n",
      "138/138 [==============================] - 0s 249us/step - loss: 0.3130 - mse: 0.3130\n",
      "Epoch 13/100\n",
      "138/138 [==============================] - 0s 250us/step - loss: 0.2932 - mse: 0.2932\n",
      "Epoch 14/100\n",
      "138/138 [==============================] - 0s 250us/step - loss: 0.2769 - mse: 0.2769\n",
      "Epoch 15/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.2588 - mse: 0.2588\n",
      "Epoch 16/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.2465 - mse: 0.2465\n",
      "Epoch 17/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.2351 - mse: 0.2351\n",
      "Epoch 18/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.2257 - mse: 0.2257\n",
      "Epoch 19/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.2174 - mse: 0.2174\n",
      "Epoch 20/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.2095 - mse: 0.2095\n",
      "Epoch 21/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.2006 - mse: 0.2006\n",
      "Epoch 22/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.1942 - mse: 0.1942\n",
      "Epoch 23/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.1889 - mse: 0.1889\n",
      "Epoch 24/100\n",
      "138/138 [==============================] - 0s 242us/step - loss: 0.1829 - mse: 0.1829\n",
      "Epoch 25/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.1775 - mse: 0.1775\n",
      "Epoch 26/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.1720 - mse: 0.1720\n",
      "Epoch 27/100\n",
      "138/138 [==============================] - 0s 248us/step - loss: 0.1680 - mse: 0.1680\n",
      "Epoch 28/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.1628 - mse: 0.1628\n",
      "Epoch 29/100\n",
      "138/138 [==============================] - 0s 249us/step - loss: 0.1580 - mse: 0.1580\n",
      "Epoch 30/100\n",
      "138/138 [==============================] - 0s 252us/step - loss: 0.1549 - mse: 0.1549\n",
      "Epoch 31/100\n",
      "138/138 [==============================] - 0s 263us/step - loss: 0.1503 - mse: 0.1503\n",
      "Epoch 32/100\n",
      "138/138 [==============================] - 0s 252us/step - loss: 0.1461 - mse: 0.1461\n",
      "Epoch 33/100\n",
      "138/138 [==============================] - 0s 255us/step - loss: 0.1429 - mse: 0.1429\n",
      "Epoch 34/100\n",
      "138/138 [==============================] - 0s 252us/step - loss: 0.1397 - mse: 0.1397\n",
      "Epoch 35/100\n",
      "138/138 [==============================] - 0s 250us/step - loss: 0.1358 - mse: 0.1358\n",
      "Epoch 36/100\n",
      "138/138 [==============================] - 0s 256us/step - loss: 0.1324 - mse: 0.1324\n",
      "Epoch 37/100\n",
      "138/138 [==============================] - 0s 239us/step - loss: 0.1296 - mse: 0.1296\n",
      "Epoch 38/100\n",
      "138/138 [==============================] - 0s 253us/step - loss: 0.1269 - mse: 0.1269\n",
      "Epoch 39/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.1256 - mse: 0.1256\n",
      "Epoch 40/100\n",
      "138/138 [==============================] - 0s 251us/step - loss: 0.1223 - mse: 0.1223\n",
      "Epoch 41/100\n",
      "138/138 [==============================] - 0s 249us/step - loss: 0.1186 - mse: 0.1186\n",
      "Epoch 42/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.1168 - mse: 0.1168\n",
      "Epoch 43/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.1137 - mse: 0.1137\n",
      "Epoch 44/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.1113 - mse: 0.1113\n",
      "Epoch 45/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.1080 - mse: 0.1080\n",
      "Epoch 46/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.1064 - mse: 0.1064\n",
      "Epoch 47/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.1040 - mse: 0.1040\n",
      "Epoch 48/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.1020 - mse: 0.1020\n",
      "Epoch 49/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.1004 - mse: 0.1004\n",
      "Epoch 50/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0983 - mse: 0.0983\n",
      "Epoch 51/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0966 - mse: 0.0966\n",
      "Epoch 52/100\n",
      "138/138 [==============================] - 0s 250us/step - loss: 0.0957 - mse: 0.0957\n",
      "Epoch 53/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0929 - mse: 0.0929\n",
      "Epoch 54/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0914 - mse: 0.0914\n",
      "Epoch 55/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0897 - mse: 0.0897\n",
      "Epoch 56/100\n",
      "138/138 [==============================] - 0s 241us/step - loss: 0.0894 - mse: 0.0894\n",
      "Epoch 57/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0869 - mse: 0.0869\n",
      "Epoch 58/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.0854 - mse: 0.0854\n",
      "Epoch 59/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.0835 - mse: 0.0835\n",
      "Epoch 60/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0821 - mse: 0.0821\n",
      "Epoch 61/100\n",
      "138/138 [==============================] - 0s 249us/step - loss: 0.0802 - mse: 0.0802\n",
      "Epoch 62/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.0791 - mse: 0.0791\n",
      "Epoch 63/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0793 - mse: 0.0793\n",
      "Epoch 64/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0796 - mse: 0.0796\n",
      "Epoch 65/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0766 - mse: 0.0766\n",
      "Epoch 66/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0763 - mse: 0.0763\n",
      "Epoch 67/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.0743 - mse: 0.0743\n",
      "Epoch 68/100\n",
      "138/138 [==============================] - 0s 242us/step - loss: 0.0735 - mse: 0.0735\n",
      "Epoch 69/100\n",
      "138/138 [==============================] - 0s 243us/step - loss: 0.0721 - mse: 0.0721\n",
      "Epoch 70/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0706 - mse: 0.0706\n",
      "Epoch 71/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.0703 - mse: 0.0703\n",
      "Epoch 72/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0690 - mse: 0.0690\n",
      "Epoch 73/100\n",
      "138/138 [==============================] - 0s 249us/step - loss: 0.0682 - mse: 0.0682\n",
      "Epoch 74/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0671 - mse: 0.0671\n",
      "Epoch 75/100\n",
      "138/138 [==============================] - 0s 241us/step - loss: 0.0645 - mse: 0.0645\n",
      "Epoch 76/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0634 - mse: 0.0634\n",
      "Epoch 77/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0624 - mse: 0.0624\n",
      "Epoch 78/100\n",
      "138/138 [==============================] - 0s 243us/step - loss: 0.0622 - mse: 0.0622\n",
      "Epoch 79/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0615 - mse: 0.0615\n",
      "Epoch 80/100\n",
      "138/138 [==============================] - 0s 246us/step - loss: 0.0610 - mse: 0.0610\n",
      "Epoch 81/100\n",
      "138/138 [==============================] - 0s 240us/step - loss: 0.0601 - mse: 0.0601\n",
      "Epoch 82/100\n",
      "138/138 [==============================] - 0s 243us/step - loss: 0.0599 - mse: 0.0599\n",
      "Epoch 83/100\n",
      "138/138 [==============================] - 0s 241us/step - loss: 0.0569 - mse: 0.0569\n",
      "Epoch 84/100\n",
      "138/138 [==============================] - 0s 248us/step - loss: 0.0553 - mse: 0.0553\n",
      "Epoch 85/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0546 - mse: 0.0546\n",
      "Epoch 86/100\n",
      "138/138 [==============================] - 0s 242us/step - loss: 0.0555 - mse: 0.0555\n",
      "Epoch 87/100\n",
      "138/138 [==============================] - 0s 243us/step - loss: 0.0539 - mse: 0.0539\n",
      "Epoch 88/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138/138 [==============================] - 0s 244us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 89/100\n",
      "138/138 [==============================] - 0s 239us/step - loss: 0.0520 - mse: 0.0520\n",
      "Epoch 90/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0515 - mse: 0.0515\n",
      "Epoch 91/100\n",
      "138/138 [==============================] - 0s 249us/step - loss: 0.0503 - mse: 0.0503\n",
      "Epoch 92/100\n",
      "138/138 [==============================] - 0s 242us/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 93/100\n",
      "138/138 [==============================] - 0s 245us/step - loss: 0.0496 - mse: 0.0496\n",
      "Epoch 94/100\n",
      "138/138 [==============================] - 0s 256us/step - loss: 0.0522 - mse: 0.0522\n",
      "Epoch 95/100\n",
      "138/138 [==============================] - 0s 248us/step - loss: 0.0543 - mse: 0.0543\n",
      "Epoch 96/100\n",
      "138/138 [==============================] - 0s 250us/step - loss: 0.0568 - mse: 0.0568\n",
      "Epoch 97/100\n",
      "138/138 [==============================] - 0s 250us/step - loss: 0.0532 - mse: 0.0532\n",
      "Epoch 98/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0495 - mse: 0.0495\n",
      "Epoch 99/100\n",
      "138/138 [==============================] - 0s 244us/step - loss: 0.0471 - mse: 0.0471\n",
      "Epoch 100/100\n",
      "138/138 [==============================] - 0s 247us/step - loss: 0.0438 - mse: 0.0438\n",
      "Predictions saved as models/DNN/dnn_outbreak.csv\n"
     ]
    }
   ],
   "source": [
    "dnn = DNN()\n",
    "dnn.train()\n",
    "dnn.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/293293\n",
      "100000/293293\n",
      "200000/293293\n",
      "Successfully saved!\n"
     ]
    }
   ],
   "source": [
    "source = 'models/DNN/dnn_outbreak.csv'\n",
    "dst = 'submissions/submission_dnn_lr_model.csv'\n",
    "output = Output('submission_dnn_lr_model.csv')\n",
    "output.save_submission(source, dst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pinball Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can calculate pinball loss of our model to see the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 2020-05-18: pinball=0.139870 mse=5.402420\n",
      "Day 2020-05-19: pinball=0.231461 mse=9.953460\n",
      "Day 2020-05-20: pinball=0.228141 mse=8.278312\n",
      "Day 2020-05-21: pinball=0.208905 mse=6.412969\n",
      "Day 2020-05-22: pinball=0.193857 mse=5.942290\n",
      "Day 2020-05-23: pinball=0.167329 mse=5.993484\n",
      "Day 2020-05-24: pinball=0.090009 mse=2.638225\n"
     ]
    }
   ],
   "source": [
    "pred_file = 'submissions/submission_dnn_lr_model.csv'\n",
    "\n",
    "start_date = '2020-05-18'\n",
    "predicted_length = 7\n",
    "date_list = generate_day_tag(start_date, predicted_length)\n",
    "for day in date_list:\n",
    "    scores = score_all_predictions(pred_file, day, '2020-05-17', key='deaths')\n",
    "    scores_mse = score_all_predictions(pred_file, day, '2020-05-17', key='deaths', mse=True)\n",
    "    print(\"Day %s: pinball=%f mse=%f\" % (day, scores[0], scores_mse[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
